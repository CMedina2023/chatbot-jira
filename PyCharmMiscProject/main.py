from fastapi import FastAPI, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pptx import Presentation
import os
import json # Necesario para parsear la respuesta JSON de Gemini
import httpx # Para realizar llamadas HTTP as√≠ncronas

app = FastAPI()

# Habilita CORS para permitir solicitudes desde cualquier origen
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Funci√≥n para cargar el contenido de un archivo PowerPoint
def cargar_conocimiento(path):
    texto = ""
    try:
        prs = Presentation(path)
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    texto += shape.text + "\n"
    except Exception as e:
        print(f"‚ùå Error al cargar el archivo PowerPoint {path}: {e}")
        # Si el archivo no existe o est√° corrupto, usa un conocimiento de fallback
        return "No se pudo cargar la documentaci√≥n. Por favor, aseg√∫rate de que 'PLAN de Capacitacion.pptx' existe y es accesible."
    return texto

# Carga la documentaci√≥n de Jira desde el archivo PowerPoint
conocimiento_jira = cargar_conocimiento("PLAN de Capacitacion.pptx")
# Si el conocimiento_jira est√° vac√≠o despu√©s de cargar, asigna un mensaje por defecto
if not conocimiento_jira.strip():
    conocimiento_jira = "La documentaci√≥n de Jira no est√° disponible en este momento."


# Endpoint para consultar al asistente de Jira
@app.post("/api/consultar")
async def consultar_jira(pregunta: str = Form(...)):
    print("üì• Pregunta recibida:", pregunta)

    # Prepara el prompt para el modelo de Gemini
    # El rol 'user' contiene la pregunta y el contexto de conocimiento
    # El rol 'system' para definir el comportamiento del asistente se integra en el 'user' parts aqu√≠ para esta llamada
    # ya que gemini-2.0-flash no soporta 'system' role directamente en el historial de chat para este tipo de interacci√≥n.
    prompt_parts = [
        {"text": "Eres un asistente de soporte t√©cnico de Jira dentro de una empresa."},
        {"text": "Utiliza la siguiente documentaci√≥n interna para responder de forma clara:"},
        {"text": conocimiento_jira},
        {"text": f"Pregunta del usuario: {pregunta}"},
        {"text": "Respuesta clara:"}
    ]

    # Prepara el payload para la API de Gemini
    payload = {
        "contents": [
            {
                "role": "user",
                "parts": prompt_parts
            }
        ]
    }

    # URL y clave de API para Gemini. La clave de API es vac√≠a ya que Canvas la inyecta autom√°ticamente.
    api_key = "AIzaSyAk_hIzA0Ts8ul-h14iXrriXTH45K6tjXM" # Canvas inyecta autom√°ticamente la clave de API en tiempo de ejecuci√≥n.
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"

    try:
        # Realiza la llamada a la API de Gemini usando httpx para solicitudes as√≠ncronas
        async with httpx.AsyncClient() as client_http:
            response = await client_http.post(
                api_url,
                headers={"Content-Type": "application/json"},
                json=payload,
                timeout=30.0 # A√±ade un timeout para evitar que la solicitud se cuelgue
            )
            response.raise_for_status() # Lanza una excepci√≥n para errores HTTP (4xx o 5xx)

            result = response.json()
            print("Response from Gemini API:", result)

            # Extrae la respuesta del modelo
            if result.get("candidates") and len(result["candidates"]) > 0 and \
               result["candidates"][0].get("content") and \
               result["candidates"][0]["content"].get("parts") and \
               len(result["candidates"][0]["content"]["parts"]) > 0:
                respuesta_llm = result["candidates"][0]["content"]["parts"][0].get("text", "").strip()
                return {"respuesta": respuesta_llm}
            else:
                print("‚ùå Estructura de respuesta inesperada de Gemini:", result)
                return {"respuesta": "‚ùå Error: La API de Gemini no devolvi√≥ una respuesta v√°lida."}

    except httpx.RequestError as e:
        print(f"‚ùå Error de red o conexi√≥n al llamar a la API de Gemini: {e}")
        return {"respuesta": f"‚ùå Error de conexi√≥n al servicio de IA: {str(e)}"}
    except httpx.HTTPStatusError as e:
        print(f"‚ùå Error en la respuesta HTTP de Gemini (C√≥digo: {e.response.status_code}): {e.response.text}")
        return {"respuesta": f"‚ùå Error del servicio de IA: {e.response.status_code} - {e.response.text}"}
    except json.JSONDecodeError as e:
        print(f"‚ùå Error al decodificar la respuesta JSON de Gemini: {e}")
        return {"respuesta": f"‚ùå Error al procesar la respuesta del servicio de IA: {str(e)}"}
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
        return {"respuesta": f"‚ùå Error al generar respuesta: {str(e)}"}

# Monta el directorio 'static' para servir archivos HTML, CSS, JS est√°ticos
app.mount("/", StaticFiles(directory="static", html=True), name="static")
